{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading libraries'''\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import gamma, dirichlet, beta, nbinom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading dataset'''\n",
    "filename = \"C:\\\\Users\\\\raoki\\\\Documents\\\\GitHub\\\\project_spring2019\\\\Data\\\\data_final.csv\"\n",
    "#filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final.csv\"\n",
    "data = pd.read_csv(filename, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing columns names'''\n",
    "lr = data.columns[[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "y = data.columns[3]\n",
    "remove = data.columns[[0,1]]\n",
    "data_complete = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 6 required positional arguments: 'latent_v', 'latent_sk', 'latent_pj', 'latent_phi', 'latent_tht', and 'prediction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-253fc1b6f045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;31m#array [intercept, gender, 15 cancer types, k genes]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mparam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 6 required positional arguments: 'latent_v', 'latent_sk', 'latent_pj', 'latent_phi', 'latent_tht', and 'prediction'"
     ]
    }
   ],
   "source": [
    "'''Class to work with model parameters'''\n",
    "class parameters:\n",
    "    def __init__(self, latent_v,latent_sk,latent_pj,latent_phi ,latent_tht, prediction):\n",
    "        self.ln = latent_v #array with parameters that are only one number \n",
    "        self.la_sk = latent_sk #array \n",
    "        self.la_pj = latent_pj #array\n",
    "        self.lm_phi = latent_phi #matrix \n",
    "        self.lm_tht = latent_tht #matrix        \n",
    "        self.p = prediction #array [intercept, gender, 15 cancer types, k genes]\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Declaring my priori values: param.ln = [0-c0,1-gamma0,2-eta,3-cj], param.la_sk, param.la_pj, \n",
    "param.lm_phi, param.lm_tht and param.p = [] \n",
    "#j=sample of patients \n",
    "#v=genes\n",
    "#k=latent\n",
    "#UPDATE PARAM '''\n",
    "def priori_l(param):\n",
    "    k = len(param.la_sk)\n",
    "    j = len(param.la_pj)\n",
    "    #Prioris on the K plate\n",
    "    s0 = 1 #define better numbers in the future\n",
    "    t0 = 1 #define better numbers in the future \n",
    "    c0 = gamma.pdf(x=param.ln[0],a = s0,scale = 1/t0)\n",
    "    a0 = 1 #define better numbers in the futureT\n",
    "    b0 = 1 #define better numbers in the future\n",
    "    gamma0 = gamma.pdf(x=param.ln[1],a = a0,scale = 1/b0)\n",
    "    sk = gamma.pdf(x=param.la_sk,a=gamma0/k,scale=1/c0)#array\n",
    "    s0 = 1\n",
    "    w0 = 1\n",
    "    eta = gamma.pdf(x=param.ln[2], a = s0, scale = w0)\n",
    "    phivk = dirichlet.pdf(param.lm_phi, np.repeat(eta,j)) #MATRIX\n",
    "    priorik = np.log(c0)+np.log(gamma0)+np.log(sk).sum()+np.log(eta)+np.log(phivk).sum()\n",
    "    #priories on the J plate\n",
    "    a0 = 1 #define better numbers in the future\n",
    "    b0 = 1 #define better numbers in the future\n",
    "    pj = beta(x=param.la_pj,a=a0,b=b0) #same numbers? #array\n",
    "    e0 = 1\n",
    "    f0 = 1\n",
    "    cj = gamma.pdf(param.ln[3], a = e0, scale = f0)\n",
    "    priorij = np.log(pj).sum()+np.log(cj) #array    \n",
    "    #prioris on K and J plate\n",
    "    thetakj = gamma.pdf(x=param.lm_tht,a=sk,scale = 1/cj) #MATRIX\n",
    "    priorikj = np.log(thetakj).sum()\n",
    "    return (priorik+priorij+priorikj)\n",
    "    \n",
    "def priori_p(param):\n",
    "    '''\n",
    "    #add prioris of logistic regression \n",
    "    #features are the theta_kj parameters and clinical info\n",
    "    #one parameter for each latent variable + one parameter for each clinical features\n",
    "    '''\n",
    "    k = len(param.la_sk)\n",
    "    mean = len(param.p)\n",
    "    sd = 5\n",
    "    mean.expend(1,np.repeat(1/15, 15))\n",
    "    sd.expend(0.05,np.repeat(0.05/15,15))\n",
    "    mean.expend(np.repeat(1,k))\n",
    "    sd.expend(np.repeat(0.05,k))\n",
    "    lr = normal.pdf(param.p,loc = mean, scale = sd) #loc/mean, scale/sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declare all the likelihood distributions in two separete functions\n",
    "#_F represents the factor model likelihood and _P the prediction model likelihood\n",
    "'''\n",
    "\n",
    "#PASS DATA ONLY WITH RELEVANT COLUMNS FOR THIS PROBLEM \n",
    "def likelihood_F(param,dataf):\n",
    "    '''phi(jk) x theta(kv) must be matrix , final dim is j patients x v genes '''\n",
    "    phi_theta = np.matmul(param.lm_phi, param.lm_tht) \n",
    "    nvj = nbinom.pmf(dataf,n = phi_theta,p= pj) #matrix and array?\n",
    "    return np.log(nvj).sum()\n",
    "\n",
    "#PASS DATA ONLY WITH RELEVANT COLUMNS FOR THIS PROBLEM \n",
    "def likelihood_P(param, datap,y):\n",
    "    '''[intercept, gender, 15 cancer types, k genes]'''\n",
    "    xw = param.p[0]\n",
    "    for i in np.arange(1,datap.shape[1]):\n",
    "        xw = xw+param.p[i]*datap[datap.columns[i-1]]\n",
    "    \n",
    "    theta = t(param.lm_th)\n",
    "    aux = datap.shape[1]\n",
    "    for j in np.arange(0,theta.shape[1]):\n",
    "        xw = xw + param.p[aux+j]*theta[theta.columns[j]]\n",
    "    \n",
    "    xwy = 0\n",
    "    for k in np.arange(1,len(y)): \n",
    "        xwy = xwy+xw[k]*y[k]\n",
    "    \n",
    "    lxp = sum(-np.log(1+np.exp(xw)))\n",
    "    #page 2 http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/bayeslogit.pdf\n",
    "    #http://www.utstat.utoronto.ca/reid/sta2201s/2014/feb14-annotated-copy.pdf\n",
    "    #https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood\n",
    "    return xwy + lxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the posterior distribution and the split of the datasets\n",
    "Note: the parameters are ok \n",
    "'''\n",
    "def posterior(param,data_F,data_P,y,k):\n",
    "    j = data.shape[0]\n",
    "    return (likelihood_F(param,data_F)+likelihood_P(param, data_P,y)+priori_l(param)+priori_p(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    return new\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Proposal distribution\n",
    "'''\n",
    "\n",
    "#Proposal values for the parameters related to the factor model \n",
    "#Repete the parameters related to prediction and only propose\n",
    "#new values for the factor analysys part\n",
    "#output is the parameters class \n",
    "def proposal_f(current):\n",
    "    new = parameters(np.random.normal(current.ln,0.05),\n",
    "                     np.random.normal(current.la_sk,0.05),\n",
    "                     np.random.normal(current.la_pj,0.05),\n",
    "                     np.random.normal(current.lm_phi,0.5),\n",
    "                     np.random.normal(current.lm_tht,0.5), \n",
    "                     current.p)\n",
    "    return new\n",
    "\n",
    "#Proposal values for the parameters related to logistic regression \n",
    "#Repete the parameters related to factor analysis part and propose\n",
    "#new values for the logistc regression parameters \n",
    "#output is the parameters class \n",
    "def proposal_p(current):\n",
    "    new = parameters(current.ln, current.la_sk, current.la_pj, \n",
    "                     current.lm_phi, current.lm_tht, \n",
    "                     np.random.normal(current.p,0.05))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creatint the MCMC for the model\n",
    "MCMC(\n",
    "startvalue = initial value for the parameters\n",
    "iterations = \n",
    "data = complete data with all columns \n",
    "k = number of latent variables\n",
    "remove, lr, y = columns names to be removed, presente only in the logistic regression part and y\n",
    ")\n",
    "'''\n",
    "def MCMC(startvalue, iterations, data,k, remove,lr,y):\n",
    "    '''Splitting dataset'''\n",
    "    data = data.drop(remove,axis = 1)\n",
    "    data_P = data[lr]\n",
    "    data_F = data.drop(lr,axis = 1)\n",
    "    y = data[y]\n",
    "    \n",
    "    '''\n",
    "    Initialization of the chains\n",
    "    Note: chain_f has elements from chain_p and vice-versa. Take care to not use incorrectly\n",
    "    '''     \n",
    "    chain_f = []\n",
    "    chain_p = []\n",
    "    chain_f.append(startvalue)\n",
    "    chain_p.append(startvalue)\n",
    "    #chain1[0]=proposalvalues1(startvalue1)\n",
    "    #chain2[0]=proposalvalues2(startvalue2)\n",
    "    \n",
    "    for i in np.arange(1,iterations):\n",
    "        '''Factor Analysis - Latent Features'''\n",
    "        #use chain_f or chain_p don't make difference here because\n",
    "        #the only parameters changed are the logistic regression and \n",
    "        #they aren't used in the factor analysis part. \n",
    "        param_new_f = proposal_f(chain_f[i-1])\n",
    "        param_cur_f = chain_f[i-1] \n",
    "\n",
    "        prob_f = np.exp(posterior(param_new,data_F,data_P,y,k)-posterior(param_curr,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_f:\n",
    "            chain_f.append(param_new_f)\n",
    "        else:\n",
    "            chain_f.append(param_cur_f) \n",
    "        '''Logistic Regression - Prediction'''\n",
    "        #chain_f[i] has the most update latent parameters and haven't changed the \n",
    "        #prediction parameters from [i-1] iteration\n",
    "        param_new_p = proposal_p(chain_f[i-1])\n",
    "        param_cur_p = chain_f[i-1]\n",
    "        \n",
    "        prob_p = np.exp(posterior(param_new,data_F,data_P,y,k)-posterior(param_curr,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_p:\n",
    "            chain_p.append(param_new_p)\n",
    "        else:\n",
    "            chain_p.append(param_cur_p)     \n",
    "\n",
    "        return chain_p, chain_f\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = parameters()\n",
    "output_p, output_f = MCMC(start,1000,data,100,remove,lr,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "class test:\n",
    "    def __init__(self, a, b, c):\n",
    "        self.a = a\n",
    "        self.b = b \n",
    "        self.c = c\n",
    "        \n",
    "a = test(1,2,3)\n",
    "print(a.a,a.b,a.c)\n",
    "\n",
    "a = test(1,2,3)\n",
    "c = test(8,9,10)\n",
    "b = [a,c]\n",
    "print(b[1].b,b[0].b)\n",
    "b.append(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 9 9\n"
     ]
    }
   ],
   "source": [
    "print(b[0].b,b[1].b,b[2].b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
