{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading libraries'''\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import gamma, dirichlet, beta, nbinom, norm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "Notes: \n",
    "1) Likelihood_F I had to add a constant to avoid log(0). Check for a better solution\n",
    "2) Proposed values aren't good, all values are rejected \n",
    "'''\n",
    "\n",
    "\n",
    "'''Important parameters I need to constantly change'''\n",
    "k = 100\n",
    "sim = 1000\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading dataset'''\n",
    "#filename = \"C:\\\\Users\\\\raoki\\\\Documents\\\\GitHub\\\\project_spring2019\\\\Data\\\\data_final.csv\"\n",
    "filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final.csv\"\n",
    "#filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final_sub.csv\"\n",
    "data = pd.read_csv(filename, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Saving time in the first part'''\n",
    "data = data.iloc[0:500, 0:300]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing columns names'''\n",
    "lr = data.columns[[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "y = data.columns[3]\n",
    "remove = data.columns[[0,1]]\n",
    "data_complete = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class to work with model parameters\n",
    "I thought about using the default values as chain starting values, \n",
    "however, i encouter problems to change the size of arrays and matrices \n",
    "according with my currently k\n",
    "'''\n",
    "class parameters:\n",
    "    def __init__(self, latent_v,latent_sk,latent_pj,latent_phi ,latent_tht, prediction):\n",
    "        self.ln = latent_v #array with parameters that are only one number [0-c0,1-gamma0,2-eta,3-cj] \n",
    "        self.la_sk = latent_sk #array \n",
    "        self.la_pj = latent_pj #array\n",
    "        self.lm_phi = latent_phi #matrix (jk)\n",
    "        self.lm_tht = latent_tht #matrix  (kv)      \n",
    "        self.p = prediction #array [intercept, gender, 15 cancer types, k genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declaring my priori values: param.ln = [0-c0,1-gamma0,2-eta,3-cj], param.la_sk, param.la_pj, \n",
    "param.lm_phi, param.lm_tht and param.p = [] \n",
    "#j=sample of patients \n",
    "#v=genes\n",
    "#k=latent\n",
    "#UPDATE PARAM \n",
    "'''\n",
    "def priori_l(param):\n",
    "    k = len(param.la_sk)\n",
    "    j = len(param.la_pj)\n",
    "    v = param.lm_phi.shape[0]\n",
    "    #Prioris on the K plate\n",
    "    s0 = 1 #define better numbers in the future\n",
    "    t0 = 1 #define better numbers in the future \n",
    "    c0 = gamma.pdf(x=param.ln[0],a = s0,scale = t0) \n",
    "    a0 = 1 #define better numbers in the futureT\n",
    "    b0 = 1 #define better numbers in the future\n",
    "    gamma0 = gamma.pdf(x=param.ln[1],a = a0,scale = b0)\n",
    "    sk = gamma.pdf(x=param.la_sk,a=param.ln[1]/k,scale=param.ln[0])#array(k) gamma(3,5): mean is 15\n",
    "    s0 = 1\n",
    "    w0 = 1\n",
    "    eta = gamma.pdf(x=param.ln[2], a = s0, scale = w0) #1\n",
    "    #print(param.lm_phi.shape,np.repeat(param.ln[2],v).shape)\n",
    "    phivk = dirichlet.pdf(x=param.lm_phi, alpha=np.repeat(param.ln[2],v)) #MATRIX #1\n",
    "    #print(phivk.shape)\n",
    "    priorik = np.log(c0)+np.log(gamma0)+np.log(sk).sum()+np.log(eta)+np.log(phivk).sum()\n",
    "    #priories on the J plate\n",
    "    a0 = 1 #define better numbers in the future\n",
    "    b0 = 1 #define better numbers in the future\n",
    "    pj = beta.pdf(x=param.la_pj,a=a0,b=b0) #same numbers? #array\n",
    "    e0 = 2\n",
    "    f0 = 9\n",
    "    cj = gamma.pdf(param.ln[3], a = e0, scale = f0)\n",
    "    priorij = np.log(pj).sum()+np.log(cj) #array    \n",
    "    #prioris on K and J plate\n",
    "    thetakj = gamma.pdf(x=np.transpose(param.lm_tht),a=param.la_sk.reshape(1,k),scale = param.ln[3]) #MATRIX \n",
    "    priorikj = np.log(thetakj).sum()\n",
    "    return (priorik+priorij+priorikj)\n",
    "  \n",
    "#increase the sd to decrease the .sum()//increase uncertainity about parameters    \n",
    "def priori_p(param):\n",
    "    '''\n",
    "    #add prioris of logistic regression \n",
    "    #features are the theta_kj parameters and clinical info\n",
    "    #one parameter for each latent variable + one parameter for each clinical features\n",
    "    '''\n",
    "    k = len(param.la_sk)\n",
    "    mean = [-len(param.p),1] #intercept and gender\n",
    "    sd = [1,0.5]\n",
    "    mean.extend(np.repeat(1/15, 15))\n",
    "    sd.extend(np.repeat(0.5/15,15))\n",
    "    mean.extend(np.repeat(1,k))\n",
    "    sd.extend(np.repeat(0.05,k))\n",
    "    lr = norm.pdf(param.p,loc = mean, scale = sd) #loc/mean, scale/sd\n",
    "    return (np.log(lr).sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declare all the likelihood distributions in two separete functions\n",
    "#_F represents the factor model likelihood and _P the prediction model likelihood\n",
    "'''\n",
    "\n",
    "#PASS DATA ONLY WITH RELEVANT COLUMNS FOR THIS PROBLEM \n",
    "def likelihood_F(param,dataf):\n",
    "    #print(dataf.head())\n",
    "    '''phi(jk) x theta(kv) must be matrix , final dim is j patients x v genes '''\n",
    "    #phi_theta = np.matmul(param.lm_phi, param.lm_tht) \n",
    "    #phi_theta = np.transpose(np.matmul(param.lm_phi, param.lm_tht)) \n",
    "    phi_theta = np.dot(param.lm_phi, param.lm_tht)\n",
    "    phi_theta = np.transpose(phi_theta)\n",
    "    #data_F = data.drop(lr,axis = 1)\n",
    "    #data_F = data_F.drop(y,axis = 1)\n",
    "    #print('lf: lm_phi ', start.lm_phi.shape, ' lm_tht shape',start.lm_tht.shape )\n",
    "    la_pj = np.repeat(start.la_pj, dataf.shape[1]).reshape(start.la_pj.shape[0],dataf.shape[1])\n",
    "    nvj = nbinom.pmf(dataf,n = phi_theta,p= la_pj) #matrix and array?\n",
    "    nvj += 0.000001  #LOOK FOR BETTER SOLUTION \n",
    "    return np.log(nvj).sum()\n",
    "\n",
    "#PASS DATA ONLY WITH RELEVANT COLUMNS FOR THIS PROBLEM \n",
    "#HERE (2854,) 100\n",
    "\n",
    "def likelihood_P(param, datap,y):\n",
    "    '''[intercept, gender, 15 cancer types, k genes]'''\n",
    "    xw = param.p[0]\n",
    "    #print(datap.head())\n",
    "    #print('xw: ', xw[0:10],'datap.shape[1]: ',datap.shape[1], 'param.p: ',param.p.shape)\n",
    "    for i in np.arange(1,datap.shape[1]):\n",
    "        xw = xw+param.p[i]*datap[datap.columns[i-1]]\n",
    "    \n",
    "    #theta = t(param.lm_tht)\n",
    "    #print('param.lm_tht shape',param.lm_tht.shape)\n",
    "    theta = np.transpose(param.lm_tht)\n",
    "    aux = datap.shape[1]\n",
    "    #print('xw shape(ok)',xw.shape, 'theta shape - wrong ',theta.shape, 'datap shape',datap.shape, 'param p shape',param.p.shape )\n",
    "    #xw shape (2854,) theta shape (1981, 100) datap shape (2854, 16) param p shape (103,)\n",
    "\n",
    "    for j in np.arange(0,theta.shape[1]):\n",
    "        xw = xw + param.p[aux+j]*theta[:,j]\n",
    "    \n",
    "    xwy = 0\n",
    "    for k in np.arange(1,len(y)): \n",
    "        xwy = xwy+xw[k]*y[k]\n",
    "    \n",
    "    lxp = sum(-np.log(1+np.exp(xw)))\n",
    "    #page 2 http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/bayeslogit.pdf\n",
    "    #http://www.utstat.utoronto.ca/reid/sta2201s/2014/feb14-annotated-copy.pdf\n",
    "    #https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood\n",
    "    return xwy + lxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the posterior distribution and the split of the datasets\n",
    "Note: the parameters are ok \n",
    "'''\n",
    "def posterior(param,data_F,data_P,y,k):\n",
    "    j = data.shape[0]\n",
    "    #print(data_F.head())\n",
    "    lf = likelihood_F(param,data_F)\n",
    "    lp = likelihood_P(param, data_P,y)\n",
    "    pl = priori_l(param)\n",
    "    pp = priori_p(param)\n",
    "    #print(lf,lp,pl,pp)\n",
    "    return (lf+lp+pl+pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Proposal distribution\n",
    "'''\n",
    "\n",
    "#Proposal values for the parameters related to the factor model \n",
    "#Repete the parameters related to prediction and only propose\n",
    "#new values for the factor analysys part\n",
    "#output is the parameters class \n",
    "def proposal_f(current):\n",
    "    new = parameters(np.random.normal(current.ln,0.005),\n",
    "                     np.random.normal(current.la_sk,0.005),\n",
    "                     np.random.normal(current.la_pj,0.005),\n",
    "                     np.random.normal(current.lm_phi,0.005),\n",
    "                     np.random.normal(current.lm_tht,0.05), \n",
    "                     current.p)\n",
    "    new.lm_phi[new.lm_phi<0] = 0.00001\n",
    "    col_sums = new.lm_phi.sum(axis=0)\n",
    "    new.lm_phi = new.lm_phi / col_sums[np.newaxis,:]\n",
    "    return new\n",
    "\n",
    "#Proposal values for the parameters related to logistic regression \n",
    "#Repete the parameters related to factor analysis part and propose\n",
    "#new values for the logistc regression parameters \n",
    "#output is the parameters class \n",
    "def proposal_p(current):\n",
    "    new = parameters(current.ln, current.la_sk, current.la_pj, \n",
    "                     current.lm_phi, current.lm_tht, \n",
    "                     np.random.normal(current.p,0.05))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creatint the MCMC for the model\n",
    "MCMC(\n",
    "startvalue = initial value for the parameters\n",
    "iterations = \n",
    "data = complete data with all columns \n",
    "k = number of latent variables\n",
    "remove, lr, y = columns names to be removed, presente only in the logistic regression part and y\n",
    ")\n",
    "'''\n",
    "def MCMC(startvalue, iterations, data,k, lr,y):\n",
    "    '''Splitting dataset'''\n",
    "    data_P = data[lr]\n",
    "    data_F = data.drop(lr,axis = 1)\n",
    "    data_F = data_F.drop(y,axis = 1)\n",
    "    y = data[y]\n",
    "    \n",
    "    '''\n",
    "    Initialization of the chains\n",
    "    Note: chain_f has elements from chain_p and vice-versa. Take care to not use incorrectly\n",
    "    '''     \n",
    "    chain_f = []\n",
    "    chain_p = []\n",
    "    chain_f.append(startvalue)\n",
    "    chain_p.append(startvalue)\n",
    "    #chain1[0]=proposalvalues1(startvalue1)\n",
    "    #chain2[0]=proposalvalues2(startvalue2)\n",
    "    \n",
    "    for i in np.arange(1,iterations):\n",
    "        '''Factor Analysis - Latent Features'''\n",
    "        #use chain_f or chain_p don't make difference here because\n",
    "        #the only parameters changed are the logistic regression and \n",
    "        #they aren't used in the factor analysis part. \n",
    "        param_new_f = proposal_f(chain_f[i-1])\n",
    "        param_cur_f = chain_f[i-1] \n",
    "        if i%100 == 0: \n",
    "            print('iteration ',i)\n",
    "        prob_f = np.exp(posterior(param_new_f,data_F,data_P,y,k)-posterior(param_cur_f,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_f:\n",
    "            chain_f.append(param_new_f)\n",
    "        else:\n",
    "            chain_f.append(param_cur_f) \n",
    "        '''Logistic Regression - Prediction'''\n",
    "        #chain_f[i] has the most update latent parameters and haven't changed the \n",
    "        #prediction parameters from [i-1] iteration\n",
    "        param_new_p = proposal_p(chain_f[i-1])\n",
    "        param_cur_p = chain_f[i-1]\n",
    "    \n",
    "        prob_p = np.exp(posterior(param_new_p,data_F,data_P,y,k)-posterior(param_cur_p,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_p:\n",
    "            chain_p.append(param_new_p)\n",
    "        else:\n",
    "            chain_p.append(param_cur_p)     \n",
    "\n",
    "    return chain_p, chain_f\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Non informative prioris: dirichlet has only 1, gamma distribution with 1 average, etc'''\n",
    "aux = len(lr)+1\n",
    "data = data.drop(remove,axis = 1)\n",
    "\n",
    "start = parameters([3,5,2,1], #ln \n",
    "                   np.repeat(15,k), #la_sk\n",
    "                   np.repeat(0.5,data.shape[0]), #la_pj\n",
    "                   np.repeat(1/(data.shape[1]-aux),(data.shape[1]-aux)*k).reshape((data.shape[1]-aux),k) ,#lm_phi v x k \n",
    "                   np.repeat(1,(data.shape[0])*k).reshape(k,(data.shape[0])), #lm_theta k x j\n",
    "                   np.concatenate(([-(k+aux)], np.repeat(1,k+aux-1))))  #p, k+aux-1  because intercept is already counted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  100\n",
      "iteration  200\n",
      "iteration  300\n",
      "iteration  400\n",
      "iteration  500\n",
      "iteration  600\n",
      "iteration  700\n",
      "iteration  800\n",
      "iteration  900\n",
      "--- 329.8726222515106 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#data = data.drop(remove,axis=1)\n",
    "output_p, output_f = MCMC(start,sim,data,k,lr,y)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4000 into shape (1000,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-5120fdd714a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0moutput_logistic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_logistic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_p\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0moutput_factor_ln\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mln\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0moutput_factor_la_sk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mla_sk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0moutput_factor_la_pj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mla_pj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0moutput_factor_lm_phi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_phi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlm_phi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 4000 into shape (1000,100)"
     ]
    }
   ],
   "source": [
    "'''Organizing outputs'''\n",
    "\n",
    "\n",
    "#Logistic Regression Parameters \n",
    "output_logistic = np.concatenate((output_p[0].p,output_p[1].p),axis = 0)\n",
    "#Factor Model parameters\n",
    "output_factor_ln = np.concatenate((output_f[0].ln,output_f[1].ln),axis = 0)\n",
    "output_factor_la_sk = np.concatenate((output_f[0].la_sk,output_f[1].la_sk),axis = 0)\n",
    "output_factor_la_pj = np.concatenate((output_f[0].la_pj,output_f[1].la_pj),axis = 0)\n",
    "#Matrix AxB is saved as a line A*B elements \n",
    "output_factor_lm_phi= np.concatenate((output_f[0].lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "output_factor_lm_tht= np.concatenate((output_f[0].lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "\n",
    "\n",
    "for i in np.arange(2,sim):\n",
    "    output_logistic = np.concatenate((output_logistic,output_p[i].p),axis = 0)\n",
    "    output_factor_ln = np.concatenate((output_factor_ln,output_f[1].ln),axis = 0)\n",
    "    output_factor_la_sk = np.concatenate((output_factor_la_sk,output_f[1].la_sk),axis = 0)\n",
    "    output_factor_la_pj = np.concatenate((output_factor_la_pj,output_f[1].la_pj),axis = 0)\n",
    "    output_factor_lm_phi = np.concatenate((output_factor_lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "    output_factor_lm_tht = np.concatenate((output_factor_lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "    \n",
    "output_logistic = output_logistic.reshape(sim,len(output_p[0].p) )    \n",
    "output_factor_ln = output_factor_ln.reshape(sim,len(output_f[0].ln) )\n",
    "output_factor_la_sk = output_factor_ln.reshape(sim,len(output_f[0].la_sk) )   \n",
    "output_factor_la_pj = output_factor_ln.reshape(sim,len(output_f[0].la_pj) )\n",
    "output_factor_lm_phi = output_factor_ln.reshape(sim,output_f[0].lm_phi.shape[0]*output_f[0].lm_phi.shape[1])   \n",
    "output_factor_lm_tht = output_factor_ln.reshape(sim,output_f[0].lm_tht.shape[0]*output_f[0].lm_tht.shape[1])\n",
    "\n",
    "np.savetxt('output_logistic.txt', output_logistic, delimiter=',')  \n",
    "np.savetxt('output_factor_ln.txt', output_factor_ln, delimiter=',')  \n",
    "np.savetxt('output_factor_la_sk.txt', output_factor_la_sk, delimiter=',')  \n",
    "np.savetxt('output_factor_la_pj.txt', output_factor_la_pj, delimiter=',')  \n",
    "np.savetxt('output_factor_lm_phi.txt', output_factor_lm_phi, delimiter=',')  \n",
    "np.savetxt('output_factor_lm_tht.txt', output_factor_lm_tht, delimiter=',')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acceptance and rejection  problem \n",
    "#create a easy way to identify paramerters based on name\n",
    "#test several parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000,) (100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(output_factor_la_sk.shape,sim*output_f[0].la_sk.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_factor_ln' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-5c1c5d284748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lr_k.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_factor_ln\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r-'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Factor Analysis - parameter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_factor_ln' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,len(output_logistic[:,0])),output_logistic[:,0], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - intercept')\n",
    "plt.savefig('lr_intercept.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,1])),output_logistic[:,1], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - gender')\n",
    "plt.savefig('lr_gender.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,10])),output_logistic[:,10], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - cancer type (one of them)')\n",
    "plt.savefig('lr_cancertype.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,30])),output_logistic[:,30], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - k (one of them)')\n",
    "plt.savefig('lr_k.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_factor_ln[:,2])),output_factor_ln[:,2], 'r-', alpha=1)\n",
    "plt.xlabel('Factor Analysis - parameter')\n",
    "plt.show()\n",
    "#plt.savefig('fa_1.png')\n",
    "\n",
    "#plt.plot(np.arange(0,len(output_factor_la_sk[:,2])),output_factor_la_sk[:,2], 'r-', alpha=1)\n",
    "#plt.xlabel('Factor Analysis - parameter')\n",
    "#plt.savefig('fa_1.png')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
