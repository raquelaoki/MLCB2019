{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading libraries'''\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import dirichlet, beta, nbinom, norm\n",
    "from scipy.special import loggamma,gamma\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "Notes: \n",
    "- use log(n)\n",
    "- Fix the saving files part, memory problms \n",
    "- Track running time\n",
    "- create a function to save files/images with a labeled name \n",
    "- track the other variables I might want to manual change to test acceptance and convergence\n",
    "- Last resource: Use c++ if compute canada is not a hand option or convergence problems. \n",
    "- lasso might help to control the parameters in the log reg\n",
    "'''\n",
    "\n",
    "\n",
    "'''Important parameters I need to constantly change'''\n",
    "k = 100\n",
    "\n",
    "sim = 100\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading dataset'''\n",
    "#filename = \"C:\\\\Users\\\\raoki\\\\Documents\\\\GitHub\\\\project_spring2019\\\\Data\\\\data_final.csv\"\n",
    "filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final.csv\"\n",
    "#filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final_sub.csv\"\n",
    "data = pd.read_csv(filename, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2854, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Saving time in the first part'''\n",
    "\n",
    "data = data.iloc[:, 0:1000]\n",
    "#data = data.sample(n=j).reset_index(drop=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing columns names'''\n",
    "lr = data.columns[[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "y = data.columns[3]\n",
    "remove = data.columns[[0,1]]\n",
    "#data_complete = data.copy()\n",
    "for i in np.arange(19,data.shape[1]):\n",
    "    data.iloc[:,i] = np.log(data.iloc[:,i]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class to work with model parameters\n",
    "I thought about using the default values as chain starting values, \n",
    "however, i encouter problems to change the size of arrays and matrices \n",
    "according with my currently k\n",
    "'''\n",
    "class parameters:\n",
    "    def __init__(self, latent_v,latent_cj,latent_sk,latent_ev,latent_phi ,latent_tht, prediction):\n",
    "        self.ln = latent_v #array with parameters that are only one number [0-c0,1-gamma0]\n",
    "        self.la_cj = latent_cj #aaray J\n",
    "        self.la_sk = latent_sk #array K\n",
    "        self.la_ev = latent_ev #array V\n",
    "        self.lm_phi = latent_phi #matrix (jk)\n",
    "        self.lm_tht = latent_tht #matrix  (kv)      \n",
    "        self.p = prediction #array [intercept, gender, 15 cancer types, k genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Proposal distribution\n",
    "NEED TO UPDATE\n",
    "\n",
    "'''\n",
    "\n",
    "#Proposal values for the parameters related to the factor model \n",
    "#Repete the parameters related to prediction and only propose\n",
    "#new values for the factor analysys part\n",
    "#output is the parameters class \n",
    "def proposal_f(current):\n",
    "    new = parameters(np.random.normal(current.ln,0.05), \n",
    "                     np.random.normal(current.la_cj,2),\n",
    "                     np.random.normal(current.la_sk,2),\n",
    "                     np.random.normal(current.la_ev,0.05),\n",
    "                     #np.random.beta(current.la_pj/2,current.la_pj/2),\n",
    "                     np.random.normal(current.lm_phi,0.000005), #remmeber that lm_phi sum up 1 in the line (genes)\n",
    "                     np.random.normal(current.lm_tht,50), #remember the average value is 1600\n",
    "                     current.p)\n",
    "    #phi and tht can't be negative \n",
    "    new.lm_phi[new.lm_phi<0] = 0.0000001 #this number needs to be smaller \n",
    "    col_sums = new.lm_phi.sum(axis=0)\n",
    "    new.lm_phi = new.lm_phi / col_sums[np.newaxis,:]\n",
    "    new.lm_tht[new.lm_tht<0]=0\n",
    "    return new\n",
    "\n",
    "#Proposal values for the parameters related to logistic regression \n",
    "#Repete the parameters related to factor analysis part and propose\n",
    "#new values for the logistc regression parameters \n",
    "#output is the parameters class \n",
    "def proposal_p(current):\n",
    "    new = parameters(current.ln,current.la_cj ,current.la_sk, #current.la_pj, \n",
    "                     current.la_ev, current.lm_phi, current.lm_tht, \n",
    "                     np.random.normal(current.p,0.5))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ratio functions'''\n",
    "def ration_f(p_new,p_cur, data_F,k):\n",
    "    '''Priori Ration'''\n",
    "    #log(1680)=7.42\n",
    "    #J is samples and V is genes\n",
    "    j = data_F.shape[0]\n",
    "    v = data_F.shape[1]\n",
    "    #A: phi_jk~Dir(eta_j)\n",
    "    A0 = k*(loggamma(np.exp(np.sum(np.log(p_cur.la_ev))))-\n",
    "           loggamma(np.exp(np.sum(np.log(p_new.la_ev)))))\n",
    "    A1 = k*(np.sum(np.log(gamma(p_new.la_ev)))-np.sum(np.log(gamma(p_cur.la_ev))))\n",
    "    A2 = np.matmul((p_new.la_ev-1),np.log(p_new.lm_phi)).sum()-np.matmul((p_cur.la_ev-1),np.log(p_cur.lm_phi)).sum()\n",
    "    #print('A', p_cur.la_ev[0:5],np.log(p_cur.la_ev)[0:5],np.sum(np.log(p_cur.la_ev)))\n",
    "    #B: eta_j~Gamma(a0,b0)\n",
    "    a0 = 1/(2*v)\n",
    "    b0 = 1/(2*v)\n",
    "    B = (a0-1)*(np.log(p_new.la_ev)-np.log(p_cur.la_ev)).sum()+(p_cur.la_ev-p_new.la_ev).sum()/b0\n",
    "    \n",
    "    #C: theta_kl~Gamma(sk,cj)\n",
    "    C0 = j*(loggamma(p_cur.la_sk).sum()-loggamma(p_new.la_sk).sum())+(\n",
    "    p_cur.la_sk.sum()*np.log(p_cur.la_cj).sum()-p_new.la_sk.sum()*np.log(p_new.la_cj).sum())\n",
    "    C1 = np.matmul(p_new.la_sk-1,np.log(p_new.lm_tht).sum(axis=1))-np.matmul(\n",
    "        p_cur.la_sk-1,np.log(p_cur.lm_tht).sum(axis=1))\n",
    "    C2 = np.divide(p_cur.lm_tht.sum(axis=0),p_cur.la_cj).sum()-np.divide(p_new.lm_tht.sum(axis=0),p_new.la_cj).sum()\n",
    "    \n",
    "    #D: sk~Gamma(gamma0,c0), gamma0 = c0 = (v*averageExpression)^0.5\n",
    "    average4 = np.sqrt(np.sqrt(v*7.42))\n",
    "    gamma0 = average4\n",
    "    c0 = average4\n",
    "    D = (gamma0-1)*(np.log(p_new.la_sk)-np.log(p_cur.la_sk)).sum()+(p_cur.la_sk-p_new.la_sk).sum()/c0\n",
    "    \n",
    "    #E: Cj~Gamma(a1,b1)\n",
    "    a1 = average4\n",
    "    b1 = average4\n",
    "    E = (a1-1)*(np.log(p_new.la_cj)-np.log(p_cur.la_cj)).sum()+(p_cur.la_cj-p_new.la_cj).sum()/b1\n",
    "    \n",
    "    #F: gamma0~Gamma(a2,b2)\n",
    "    average8 = np.sqrt(average4)\n",
    "    a2 = average8\n",
    "    b2 = average8\n",
    "    F = (a2-1)*(np.log(p_new.ln[1])-np.log(p_cur.ln[1]))+(p_cur.ln[1]-p_new.ln[1])/b2\n",
    "    \n",
    "    #G: c0~Gamma(a3,b3)\n",
    "    a3 = average8\n",
    "    b3 = average8\n",
    "    G = (a3-1)*(np.log(p_new.ln[0])-np.log(p_cur.ln[0]))+(p_cur.ln[0]-p_new.ln[0])/b3\n",
    "    '''Likelihood'''\n",
    "    #I: n_vj~Poisson(phi_vk theta_kj)\n",
    "    I0 = np.transpose(np.log(np.matmul(p_new.lm_phi,p_new.lm_tht))-np.log(np.matmul(p_cur.lm_phi,p_cur.lm_tht)))\n",
    "    #print(I0.shape,I0[0:5],data_F.head())\n",
    "    I1 = np.multiply(data_F.as_matrix(),I0).sum()\n",
    "    I2 = (np.matmul(p_cur.lm_phi,p_cur.lm_tht)-np.matmul(p_new.lm_phi,p_new.lm_tht)).sum()\n",
    "    #print('here',A0,A1,A2,B,C0,C1,C2,D,E,F,G,I1,I2,'end')\n",
    "    return (A0+A1+A2+B+C0+C1+C2+D+E+F+G+I1+I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_p(p_new,p_cur, data_P,k,y):\n",
    "    sigma0 = 5\n",
    "    sigma = 2\n",
    "    mu0 = -len(p_new.p)\n",
    "    mu = 1\n",
    "    #H: beta~normal(mu,sigma2)\n",
    "    H0 = (1/(sigma0*sigma0))*((p_cur.p[0]-mu0)*(p_cur.p[0]-mu0)-(p_new.p[0]-mu0)*(p_new.p[0]-mu0))*0.5\n",
    "    H1 = (np.multiply((p_cur.p-mu),(p_cur.p-mu))-np.multiply((p_new.p-mu),(p_new.p-mu))).sum()\n",
    "    H1 = H1 - (p_cur.p[0]-mu)*(p_cur.p[0]-mu)+(p_new.p[0]-mu)*(p_new.p[0]-mu)\n",
    "    H1 = (H1*(len(p_new.p)-1)/sigma)*0.5\n",
    "    \n",
    "    #J: y~Log(xbeta)\n",
    "    data_P = data_P.as_matrix()\n",
    "    #data_P = np.append(np.array(np.repeat(1,data_P.shape[0])), data_P, axis=1)\n",
    "    data_P = np.hstack((np.array(np.repeat(1,data_P.shape[0])).reshape(data_P.shape[0],1),data_P))\n",
    "    data_P = np.hstack((data_P,np.transpose(p_cur.lm_tht)))\n",
    "    xw_new = np.dot(data_P,p_new.p)\n",
    "    xw_cur = np.dot(data_P,p_cur.p)\n",
    "    J = ((-np.log(1+np.exp(xw_new))+np.dot(y,xw_new))-(-np.log(1+np.exp(xw_cur))+np.dot(y,xw_cur))).sum()\n",
    "    return (H0+H1+J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creatint the MCMC for the model\n",
    "MCMC(\n",
    "startvalue = initial value for the parameters\n",
    "iterations = \n",
    "data = complete data with all columns \n",
    "k = number of latent variables\n",
    "remove, lr, y = columns names to be removed, presente only in the logistic regression part and y\n",
    ")\n",
    "'''\n",
    "def MCMC(startvalue, iterations, data,k, lr,y):\n",
    "    '''Splitting dataset'''\n",
    "    data_P = data[lr]\n",
    "    data_F = data.drop(lr,axis = 1)\n",
    "    data_F = data_F.drop(y,axis = 1)\n",
    "    y = data[y]\n",
    "    a_P = 0\n",
    "    a_F = 0\n",
    "    '''\n",
    "    Initialization of the chains\n",
    "    Note: chain_f has elements from chain_p and vice-versa. Take care to not use incorrectly\n",
    "    '''     \n",
    "    chain_f = []\n",
    "    chain_p = []\n",
    "    chain_f.append(startvalue)\n",
    "    chain_p.append(startvalue)\n",
    "     \n",
    "    for i in np.arange(1,iterations):\n",
    "        '''Factor Analysis - Latent Features'''\n",
    "        #use chain_f or chain_p don't make difference here because\n",
    "        #the only parameters changed are the logistic regression and \n",
    "        #they aren't used in the factor analysis part. \n",
    "        param_new_f = proposal_f(chain_f[i-1])\n",
    "        param_cur_f = chain_f[i-1] \n",
    "        if i%10 == 0: \n",
    "            a = a_F*10/i\n",
    "            b = a_P*10/i\n",
    "            print('iteration ',i,' acceptance ', \"%0.2f\" % a,'-', \"%0.2f\" % b)\n",
    "        #prob_f = np.exp(posterior(param_new_f,data_F,data_P,y,k)-posterior(param_cur_f,data_F,data_P,y,k))\n",
    "        prob_f = np.exp(ration_f(param_new_f,param_cur_f, data_F,k))\n",
    "        if np.random.uniform(0,1,1)<prob_f:\n",
    "            chain_f.append(param_new_f)\n",
    "            a_F+=1\n",
    "        else:\n",
    "            chain_f.append(param_cur_f) \n",
    "        '''Logistic Regression - Prediction'''\n",
    "        #chain_f[i] has the most update latent parameters and haven't changed the \n",
    "        #prediction parameters from [i-1] iteration\n",
    "        param_new_p = proposal_p(chain_f[i-1])\n",
    "        param_cur_p = chain_f[i-1]\n",
    "    \n",
    "        prob_p = np.exp(ratio_p(param_new_p,param_cur_p,data_P,k,y))\n",
    "        if np.random.uniform(0,1,1)<prob_p:\n",
    "            chain_p.append(param_new_p)\n",
    "            a_P+=1\n",
    "        else:\n",
    "            chain_p.append(param_cur_p)     \n",
    "\n",
    "    return chain_p, chain_f, a_P, a_F\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Non informative prioris: dirichlet has only 1, gamma distribution with 1 average, etc'''\n",
    "#UPDATE NUMBERS ACCORDING WITH POISSON AND LOG(N)\n",
    "aux = len(lr)+1\n",
    "data = data.drop(remove,axis = 1)\n",
    "v = (data.shape[1]-aux)\n",
    "j = data.shape[0]\n",
    "start = parameters([3,6],#,5,41], #ln \n",
    "                   np.repeat(41,j), #la_cj\n",
    "                   np.repeat(15,k), #la_sk\n",
    "                   np.repeat(1.2,v), #la_ev\n",
    "                   np.repeat(1/(data.shape[1]-aux),(data.shape[1]-aux)*k).reshape((data.shape[1]-aux),k),#lm_phi v x k \n",
    "                   np.repeat(1600,(data.shape[0])*k).reshape(k,(data.shape[0])), #lm_theta k x j\n",
    "                   np.concatenate(([-(k*1600)], np.repeat(1,k+aux-1))))  #p, k+aux-1  because intercept is already counted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in long_scalars\n",
      "  import sys\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in long_scalars\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in subtract\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\numpy\\core\\_methods.py:36: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial)\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:53: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  10  acceptance  7.00 - 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in log\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:41: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  20  acceptance  6.00 - 2.00\n",
      "iteration  30  acceptance  5.00 - 2.00\n",
      "iteration  40  acceptance  4.00 - 2.75\n",
      "iteration  50  acceptance  3.20 - 2.80\n",
      "iteration  60  acceptance  2.67 - 2.50\n",
      "iteration  70  acceptance  2.43 - 2.29\n",
      "iteration  80  acceptance  2.12 - 2.12\n",
      "iteration  90  acceptance  1.89 - 2.22\n",
      "--- 11.349133729934692 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#data = data.drop(remove,axis=1)\n",
    "sim = 100\n",
    "start_time = time.time()\n",
    "output_p, output_f, acept_P,acept_F = MCMC(start,sim,data,k,lr,y)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "#Don't make sense, some operations must be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[2,2],[3,3]]\n",
    "b = [[4,4],[3,3]]\n",
    "print(a,b)\n",
    "np.multiply(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing outputs'''\n",
    "\n",
    "#TRANSFORM IN A FUNCTION TO STOP HAVE MEMORY PROBLEMS \n",
    "\n",
    "#Logistic Regression Parameters \n",
    "output_logistic = np.concatenate((output_p[0].p,output_p[1].p),axis = 0)\n",
    "#Factor Model parameters\n",
    "output_factor_ln = np.concatenate((output_f[0].ln,output_f[1].ln),axis = 0)\n",
    "output_factor_la_sk = np.concatenate((output_f[0].la_sk,output_f[1].la_sk),axis = 0)\n",
    "#Matrix AxB is saved as a line A*B elements \n",
    "output_factor_lm_phi= np.concatenate((output_f[0].lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "output_factor_lm_tht= np.concatenate((output_f[0].lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "\n",
    "\n",
    "for i in np.arange(2,sim):\n",
    "    output_logistic = np.concatenate((output_logistic,output_p[i].p),axis = 0)\n",
    "    output_factor_ln = np.concatenate((output_factor_ln,output_f[1].ln),axis = 0)\n",
    "    output_factor_la_sk = np.concatenate((output_factor_la_sk,output_f[1].la_sk),axis = 0)\n",
    "\n",
    "output_logistic = output_logistic.reshape(sim,len(output_p[0].p) )    \n",
    "output_factor_ln = output_factor_ln.reshape(sim,len(output_f[0].ln) )\n",
    "output_factor_la_sk = output_factor_la_sk.reshape(sim,len(output_f[0].la_sk) )   \n",
    "\n",
    "np.savetxt('Data\\\\output_logistic.txt', output_logistic, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_ln.txt', output_factor_ln, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_la_sk.txt', output_factor_la_sk, delimiter=',')  \n",
    "\n",
    "'''\n",
    "    output_factor_lm_phi = np.concatenate((output_factor_lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "    output_factor_lm_tht = np.concatenate((output_factor_lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "    \n",
    "output_factor_lm_phi = output_factor_lm_phi.reshape(sim,output_f[0].lm_phi.shape[0]*output_f[0].lm_phi.shape[1])   \n",
    "output_factor_lm_tht = output_factor_lm_tht.reshape(sim,output_f[0].lm_tht.shape[0]*output_f[0].lm_tht.shape[1])\n",
    "\n",
    "np.savetxt('Data\\\\output_factor_lm_phi.txt', output_factor_lm_phi, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_lm_tht.txt', output_factor_lm_tht, delimiter=',')  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acceptance and rejection  problem \n",
    "#create a easy way to identify paramerters based on name\n",
    "#test several parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(output_logistic[:,0])),output_logistic[:,0], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - intercept')\n",
    "plt.savefig('Data\\\\lr_intercept.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,1])),output_logistic[:,1], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - gender')\n",
    "plt.savefig('Data\\\\lr_gender.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,10])),output_logistic[:,10], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - cancer type (one of them)')\n",
    "plt.savefig('Data\\\\lr_cancertype.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,30])),output_logistic[:,30], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - k (one of them)')\n",
    "plt.savefig('Data\\\\lr_k.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_factor_ln[:,2])),output_factor_ln[:,2], 'r-', alpha=1)\n",
    "plt.xlabel('Factor Analysis - parameter')\n",
    "plt.savefig('Data\\\\fa_1.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
