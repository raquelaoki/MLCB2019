{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading libraries'''\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import gamma, dirichlet, beta, nbinom, norm\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "Notes: \n",
    "1) Likelihood_F I had to add a constant to avoid log(0). Check for a better solution\n",
    "2) Proposed values aren't good, all values are rejected \n",
    "3) Check likelihood_P\n",
    "4) Priori too much weight? \n",
    "5) Add track of accetance rate\n",
    "6) Proposal values too bad\n",
    "7) Track running time\n",
    "8) create a function to save files/images with a labeled name \n",
    "9) track the other variables I might want to manual change to test acceptance and convergence\n",
    "10) Rewrite the priori and likelihood removing the distributions and using the equations, cutting what\n",
    "i don't need. I think using like I'm using won't converge. \n",
    "11) Use c++ if compute canada is not a hand option or convergence problems. \n",
    "'''\n",
    "\n",
    "\n",
    "'''Important parameters I need to constantly change'''\n",
    "k = 100\n",
    "sim = 1000\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading dataset'''\n",
    "#filename = \"C:\\\\Users\\\\raoki\\\\Documents\\\\GitHub\\\\project_spring2019\\\\Data\\\\data_final.csv\"\n",
    "filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final.csv\"\n",
    "#filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final_sub.csv\"\n",
    "data = pd.read_csv(filename, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Saving time in the first part'''\n",
    "data = data.iloc[0:500, 0:300]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing columns names'''\n",
    "lr = data.columns[[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "y = data.columns[3]\n",
    "remove = data.columns[[0,1]]\n",
    "data_complete = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class to work with model parameters\n",
    "I thought about using the default values as chain starting values, \n",
    "however, i encouter problems to change the size of arrays and matrices \n",
    "according with my currently k\n",
    "'''\n",
    "class parameters:\n",
    "    def __init__(self, latent_v,latent_sk,latent_pj,latent_phi ,latent_tht, prediction):\n",
    "        self.ln = latent_v #array with parameters that are only one number [0-c0,1-gamma0,2-eta,3-cj] \n",
    "        self.la_sk = latent_sk #array \n",
    "        self.la_pj = latent_pj #array\n",
    "        self.lm_phi = latent_phi #matrix (jk)\n",
    "        self.lm_tht = latent_tht #matrix  (kv)      \n",
    "        self.p = prediction #array [intercept, gender, 15 cancer types, k genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declaring my priori values: param.ln = [0-c0,1-gamma0,2-eta,3-cj], param.la_sk, param.la_pj, \n",
    "param.lm_phi, param.lm_tht and param.p = [] \n",
    "#j=sample of patients \n",
    "#v=genes\n",
    "#k=latent\n",
    "#UPDATE PARAM \n",
    "'''\n",
    "def priori_l(param):\n",
    "    k = len(param.la_sk)\n",
    "    j = len(param.la_pj)\n",
    "    v = param.lm_phi.shape[0]\n",
    "    #Prioris on the K plate\n",
    "    s0 = 2.4 \n",
    "    t0 = 2.4 \n",
    "    c0 = gamma.pdf(x=param.ln[0],a = s0,scale = t0) #mean 6\n",
    "    a0 = 2.4 \n",
    "    b0 = 2.4 \n",
    "    gamma0 = gamma.pdf(x=param.ln[1],a = a0,scale = b0) #mean 6\n",
    "    sk = gamma.pdf(x=param.la_sk,a=param.ln[1],scale=param.ln[0])#array(k)  mean is 40\n",
    "    s0 = 1\n",
    "    w0 = 1\n",
    "    eta = gamma.pdf(x=param.ln[2], a = s0, scale = w0) #CHECH HERE AGAIN\n",
    "    phivk = dirichlet.pdf(x=param.lm_phi, alpha=np.repeat(param.ln[2],v)) #MATRIX #1\n",
    "    priorik = np.log(c0)+np.log(gamma0)+np.log(sk).sum()+np.log(eta)+np.log(phivk).sum()\n",
    "    #priories on the J plate\n",
    "    a0 = 2 \n",
    "    b0 = 2 \n",
    "    pj = beta.pdf(x=param.la_pj,a=a0,b=b0)  #beta(2,2) is symetric and centred in 0.5\n",
    "    e0 = 6.4\n",
    "    f0 = 6.4\n",
    "    cj = gamma.pdf(param.ln[3], a = e0, scale = f0) #mean is 40\n",
    "    priorij = np.log(pj).sum()+np.log(cj) #array    \n",
    "    #prioris on K and J plate\n",
    "    thetakj = gamma.pdf(x=np.transpose(param.lm_tht),a=param.la_sk.reshape(1,k),scale = param.ln[3]) #MATRIX \n",
    "    priorikj = np.log(thetakj).sum()\n",
    "    return (priorik+priorij+priorikj)\n",
    "  \n",
    "#increase the sd to decrease the .sum()//increase uncertainity about parameters    \n",
    "def priori_p(param):\n",
    "    '''\n",
    "    #add prioris of logistic regression \n",
    "    #features are the theta_kj parameters and clinical info\n",
    "    #one parameter for each latent variable + one parameter for each clinical features\n",
    "    '''\n",
    "    k = len(param.la_sk)\n",
    "    mean = [-len(param.p),1] #intercept and gender\n",
    "    sd = [10,5]\n",
    "    mean.extend(np.repeat(1/15, 15))\n",
    "    sd.extend(np.repeat(3,15))\n",
    "    mean.extend(np.repeat(1,k))\n",
    "    sd.extend(np.repeat(5,k))\n",
    "    lr = norm.pdf(param.p,loc = mean, scale = sd) #loc/mean, scale/sd\n",
    "    return (np.log(lr).sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Declare all the likelihood distributions in two separete functions\n",
    "#_F represents the factor model likelihood and _P the prediction model likelihood\n",
    "'''\n",
    "\n",
    "#PASS DATA ONLY WITH RELEVANT COLUMNS FOR THIS PROBLEM \n",
    "def likelihood_F(param,dataf):\n",
    "    '''phi(jk) x theta(kv) must be matrix , final dim is j patients x v genes '''\n",
    "    phi_theta = np.dot(param.lm_phi, param.lm_tht)\n",
    "    phi_theta = np.transpose(phi_theta)\n",
    "    la_pj = np.repeat(param.la_pj, dataf.shape[1]).reshape(param.la_pj.shape[0],dataf.shape[1])\n",
    "    nvj = nbinom.pmf(dataf,n = phi_theta,p= la_pj) #matrix and array?\n",
    "    nvj += 0.000001  #LOOK FOR BETTER SOLUTION \n",
    "    return np.log(nvj).sum()\n",
    "\n",
    "\n",
    "def likelihood_P(param, datap,y):\n",
    "    '''[intercept, gender, 15 cancer types, k genes]'''\n",
    "    xw = param.p[0]\n",
    "    for i in np.arange(1,datap.shape[1]):\n",
    "        xw = xw+param.p[i]*datap[datap.columns[i-1]]\n",
    "    \n",
    "    theta = np.transpose(param.lm_tht)\n",
    "    aux = datap.shape[1]\n",
    "\n",
    "    for j in np.arange(0,theta.shape[1]):\n",
    "        xw = xw + param.p[aux+j]*theta[:,j]\n",
    "    \n",
    "    xwy = 0\n",
    "    for k in np.arange(1,len(y)): \n",
    "        xwy = xwy+xw[k]*y[k]\n",
    "    \n",
    "    lxp = sum(-np.log(1+np.exp(xw)))\n",
    "    #page 2 http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/bayeslogit.pdf\n",
    "    #http://www.utstat.utoronto.ca/reid/sta2201s/2014/feb14-annotated-copy.pdf\n",
    "    #https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood\n",
    "    return xwy + lxp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definition of the posterior distribution and the split of the datasets\n",
    "Note: the parameters are ok \n",
    "'''\n",
    "def posterior(param,data_F,data_P,y,k):\n",
    "    j = data.shape[0]\n",
    "    lf = likelihood_F(param,data_F)\n",
    "    lp = likelihood_P(param, data_P,y)\n",
    "    pl = priori_l(param)\n",
    "    pp = priori_p(param)\n",
    "    #print(lf,lp,pl,pp)\n",
    "    return (lf+lp+pl+pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Proposal distribution\n",
    "'''\n",
    "\n",
    "#Proposal values for the parameters related to the factor model \n",
    "#Repete the parameters related to prediction and only propose\n",
    "#new values for the factor analysys part\n",
    "#output is the parameters class \n",
    "def proposal_f(current):\n",
    "    new = parameters(np.random.normal(current.ln,0.0005),\n",
    "                     np.random.normal(current.la_sk,0.0005),\n",
    "                     np.random.beta(current.la_pj/2,current.la_pj/2),\n",
    "                     np.random.normal(current.lm_phi,0.0005),\n",
    "                     np.random.normal(current.lm_tht,0.005), \n",
    "                     current.p)\n",
    "    new.lm_phi[new.lm_phi<0] = 0.00001\n",
    "    col_sums = new.lm_phi.sum(axis=0)\n",
    "    new.lm_phi = new.lm_phi / col_sums[np.newaxis,:]\n",
    "    return new\n",
    "\n",
    "#Proposal values for the parameters related to logistic regression \n",
    "#Repete the parameters related to factor analysis part and propose\n",
    "#new values for the logistc regression parameters \n",
    "#output is the parameters class \n",
    "def proposal_p(current):\n",
    "    new = parameters(current.ln, current.la_sk, current.la_pj, \n",
    "                     current.lm_phi, current.lm_tht, \n",
    "                     np.random.normal(current.p,0.05))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creatint the MCMC for the model\n",
    "MCMC(\n",
    "startvalue = initial value for the parameters\n",
    "iterations = \n",
    "data = complete data with all columns \n",
    "k = number of latent variables\n",
    "remove, lr, y = columns names to be removed, presente only in the logistic regression part and y\n",
    ")\n",
    "'''\n",
    "def MCMC(startvalue, iterations, data,k, lr,y):\n",
    "    '''Splitting dataset'''\n",
    "    data_P = data[lr]\n",
    "    data_F = data.drop(lr,axis = 1)\n",
    "    data_F = data_F.drop(y,axis = 1)\n",
    "    y = data[y]\n",
    "    a_P = 0\n",
    "    a_F = 0\n",
    "    '''\n",
    "    Initialization of the chains\n",
    "    Note: chain_f has elements from chain_p and vice-versa. Take care to not use incorrectly\n",
    "    '''     \n",
    "    chain_f = []\n",
    "    chain_p = []\n",
    "    chain_f.append(startvalue)\n",
    "    chain_p.append(startvalue)\n",
    "     \n",
    "    for i in np.arange(1,iterations):\n",
    "        '''Factor Analysis - Latent Features'''\n",
    "        #use chain_f or chain_p don't make difference here because\n",
    "        #the only parameters changed are the logistic regression and \n",
    "        #they aren't used in the factor analysis part. \n",
    "        param_new_f = proposal_f(chain_f[i-1])\n",
    "        param_cur_f = chain_f[i-1] \n",
    "        if i%100 == 0: \n",
    "            print('iteration ',i,' acceptance ', a_F*100/i,'-', a_P*100/i)\n",
    "        prob_f = np.exp(posterior(param_new_f,data_F,data_P,y,k)-posterior(param_cur_f,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_f:\n",
    "            chain_f.append(param_new_f)\n",
    "            a_F+=1\n",
    "        else:\n",
    "            chain_f.append(param_cur_f) \n",
    "        '''Logistic Regression - Prediction'''\n",
    "        #chain_f[i] has the most update latent parameters and haven't changed the \n",
    "        #prediction parameters from [i-1] iteration\n",
    "        param_new_p = proposal_p(chain_f[i-1])\n",
    "        param_cur_p = chain_f[i-1]\n",
    "    \n",
    "        prob_p = np.exp(posterior(param_new_p,data_F,data_P,y,k)-posterior(param_cur_p,data_F,data_P,y,k))\n",
    "        if np.random.uniform(0,1,1)<prob_p:\n",
    "            chain_p.append(param_new_p)\n",
    "            a_P+=1\n",
    "        else:\n",
    "            chain_p.append(param_cur_p)     \n",
    "\n",
    "    return chain_p, chain_f, a_P, a_F\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Non informative prioris: dirichlet has only 1, gamma distribution with 1 average, etc'''\n",
    "aux = len(lr)+1\n",
    "data = data.drop(remove,axis = 1)\n",
    "\n",
    "start = parameters([3,6,2,41], #ln \n",
    "                   np.repeat(15,k), #la_sk\n",
    "                   np.repeat(0.5,data.shape[0]), #la_pj\n",
    "                   np.repeat(1/(data.shape[1]-aux),(data.shape[1]-aux)*k).reshape((data.shape[1]-aux),k) ,#lm_phi v x k \n",
    "                   np.repeat(1600,(data.shape[0])*k).reshape(k,(data.shape[0])), #lm_theta k x j\n",
    "                   np.concatenate(([-(k+aux)], np.repeat(1,k+aux-1))))  #p, k+aux-1  because intercept is already counted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:37: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\raque\\Anaconda3\\envs\\py37\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  100  acceptance  0.0 - 0.0\n",
      "iteration  200  acceptance  0.0 - 0.0\n",
      "iteration  300  acceptance  0.0 - 0.0\n",
      "iteration  400  acceptance  0.0 - 0.0\n",
      "iteration  500  acceptance  0.0 - 0.0\n",
      "iteration  600  acceptance  0.0 - 0.0\n",
      "iteration  700  acceptance  0.0 - 0.0\n",
      "iteration  800  acceptance  0.0 - 0.0\n",
      "iteration  900  acceptance  0.0 - 0.0\n",
      "--- 294.1316878795624 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#data = data.drop(remove,axis=1)\n",
    "\n",
    "start_time = time.time()\n",
    "output_p, output_f, acept_P,acept_F = MCMC(start,sim,data,k,lr,y)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing outputs'''\n",
    "\n",
    "\n",
    "#Logistic Regression Parameters \n",
    "output_logistic = np.concatenate((output_p[0].p,output_p[1].p),axis = 0)\n",
    "#Factor Model parameters\n",
    "output_factor_ln = np.concatenate((output_f[0].ln,output_f[1].ln),axis = 0)\n",
    "output_factor_la_sk = np.concatenate((output_f[0].la_sk,output_f[1].la_sk),axis = 0)\n",
    "output_factor_la_pj = np.concatenate((output_f[0].la_pj,output_f[1].la_pj),axis = 0)\n",
    "#Matrix AxB is saved as a line A*B elements \n",
    "output_factor_lm_phi= np.concatenate((output_f[0].lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "output_factor_lm_tht= np.concatenate((output_f[0].lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "\n",
    "\n",
    "for i in np.arange(2,sim):\n",
    "    output_logistic = np.concatenate((output_logistic,output_p[i].p),axis = 0)\n",
    "    output_factor_ln = np.concatenate((output_factor_ln,output_f[1].ln),axis = 0)\n",
    "    output_factor_la_sk = np.concatenate((output_factor_la_sk,output_f[1].la_sk),axis = 0)\n",
    "    output_factor_la_pj = np.concatenate((output_factor_la_pj,output_f[1].la_pj),axis = 0)\n",
    "    output_factor_lm_phi = np.concatenate((output_factor_lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "    output_factor_lm_tht = np.concatenate((output_factor_lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "    \n",
    "output_logistic = output_logistic.reshape(sim,len(output_p[0].p) )    \n",
    "output_factor_ln = output_factor_ln.reshape(sim,len(output_f[0].ln) )\n",
    "output_factor_la_sk = output_factor_la_sk.reshape(sim,len(output_f[0].la_sk) )   \n",
    "output_factor_la_pj = output_factor_la_pj.reshape(sim,len(output_f[0].la_pj) )\n",
    "output_factor_lm_phi = output_factor_lm_phi.reshape(sim,output_f[0].lm_phi.shape[0]*output_f[0].lm_phi.shape[1])   \n",
    "output_factor_lm_tht = output_factor_lm_tht.reshape(sim,output_f[0].lm_tht.shape[0]*output_f[0].lm_tht.shape[1])\n",
    "\n",
    "np.savetxt('Data\\\\output_logistic.txt', output_logistic, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_ln.txt', output_factor_ln, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_la_sk.txt', output_factor_la_sk, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_la_pj.txt', output_factor_la_pj, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_lm_phi.txt', output_factor_lm_phi, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_lm_tht.txt', output_factor_lm_tht, delimiter=',')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acceptance and rejection  problem \n",
    "#create a easy way to identify paramerters based on name\n",
    "#test several parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.945590944741246"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(0,len(output_logistic[:,0])),output_logistic[:,0], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - intercept')\n",
    "plt.savefig('Data\\\\lr_intercept.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,1])),output_logistic[:,1], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - gender')\n",
    "plt.savefig('Data\\\\lr_gender.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,10])),output_logistic[:,10], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - cancer type (one of them)')\n",
    "plt.savefig('Data\\\\lr_cancertype.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,30])),output_logistic[:,30], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - k (one of them)')\n",
    "plt.savefig('Data\\\\lr_k.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_factor_ln[:,2])),output_factor_ln[:,2], 'r-', alpha=1)\n",
    "plt.xlabel('Factor Analysis - parameter')\n",
    "plt.savefig('Data\\\\fa_1.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
