{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading libraries'''\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from scipy.stats import dirichlet, beta, nbinom, norm\n",
    "from scipy.special import loggamma,gamma\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "'''\n",
    "Notes: \n",
    "- lm(theta) is inf, but don't make sense because average theta is 7.42. \n",
    "- invest nan part\n",
    "- when i add more columns the aceptance rate goes to 0. \n",
    "- Fix the saving files part, memory problms \n",
    "- Track running time\n",
    "- create a function to save files/images with a labeled name \n",
    "'''\n",
    "\n",
    "\n",
    "'''Important parameters I need to constantly change'''\n",
    "k = 100\n",
    "\n",
    "sim = 500\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading dataset'''\n",
    "#filename = \"C:\\\\Users\\\\raoki\\\\Documents\\\\GitHub\\\\project_spring2019\\\\Data\\\\data_final.csv\"\n",
    "filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final.csv\"\n",
    "#filename = \"C:\\\\Users\\\\raque\\\\Google Drive\\\\SFU\\\\Project 2 - Spring 2019\\\\Data\\\\data_final_sub.csv\"\n",
    "data = pd.read_csv(filename, sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Saving time in the first part'''\n",
    "\n",
    "data = data.iloc[:, 0:1000]\n",
    "#data = data.sample(n=j).reset_index(drop=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing columns names'''\n",
    "lr = data.columns[[2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "y = data.columns[3]\n",
    "remove = data.columns[[0,1]]\n",
    "#data_complete = data.copy()\n",
    "for i in np.arange(19,data.shape[1]):\n",
    "    data.iloc[:,i] = np.log(data.iloc[:,i]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Class to work with model parameters\n",
    "I thought about using the default values as chain starting values, \n",
    "however, i encouter problems to change the size of arrays and matrices \n",
    "according with my currently k\n",
    "'''\n",
    "class parameters:\n",
    "    def __init__(self, latent_v,latent_cj,latent_sk,latent_ev,latent_phi ,latent_tht, prediction):\n",
    "        self.ln = latent_v #array with parameters that are only one number [0-c0,1-gamma0]\n",
    "        self.la_cj = latent_cj #aaray J\n",
    "        self.la_sk = latent_sk #array K\n",
    "        self.la_ev = latent_ev #array V\n",
    "        self.lm_phi = latent_phi #matrix (jk)\n",
    "        self.lm_tht = latent_tht #matrix  (kv)      \n",
    "        self.p = prediction #array [intercept, gender, 15 cancer types, k genes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Proposal distribution\n",
    "NEED TO UPDATE\n",
    "\n",
    "'''\n",
    "\n",
    "#Proposal values for the parameters related to the factor model \n",
    "#Repete the parameters related to prediction and only propose\n",
    "#new values for the factor analysys part\n",
    "#output is the parameters class \n",
    "def proposal_f(current):\n",
    "    new = parameters(np.random.normal(current.ln,0.05), \n",
    "                     np.random.normal(current.la_cj,0.1),\n",
    "                     np.random.normal(current.la_sk,0.1),\n",
    "                     np.random.normal(current.la_ev,0.05),\n",
    "                     np.random.normal(current.lm_phi,0.000005), #remmeber that lm_phi sum up 1 in the line (genes)\n",
    "                     np.random.normal(current.lm_tht,1), #remember the average value is 7.42\n",
    "                     current.p)\n",
    "    #phi and tht can't be negative \n",
    "    new.lm_phi[new.lm_phi<0] = 0.0000001 #this number needs to be smaller \n",
    "    col_sums = new.lm_phi.sum(axis=0)\n",
    "    new.lm_phi = new.lm_phi / col_sums[np.newaxis,:]\n",
    "    new.lm_tht[new.lm_tht<0]=0\n",
    "    new.lm_tht[new.lm_tht<0] = 0.0000001\n",
    "    col_sums1 = new.lm_tht.sum(axis=0)\n",
    "    new.lm_tht = new.lm_tht / col_sums1[np.newaxis,:]\n",
    "    \n",
    "    return new\n",
    "\n",
    "#Proposal values for the parameters related to logistic regression \n",
    "#Repete the parameters related to factor analysis part and propose\n",
    "#new values for the logistc regression parameters \n",
    "#output is the parameters class \n",
    "def proposal_p(current):\n",
    "    new = parameters(current.ln,current.la_cj ,current.la_sk, #current.la_pj, \n",
    "                     current.la_ev, current.lm_phi, current.lm_tht, \n",
    "                     np.random.normal(current.p,0.05))\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ratio functions'''\n",
    "def ration_f(p_new,p_cur, data_F,k):\n",
    "    '''Priori Ration'''\n",
    "    #log(1680)=7.42\n",
    "    #J is samples and V is genes\n",
    "    j = data_F.shape[0]\n",
    "    v = data_F.shape[1]\n",
    "    #A: phi_jk~Dir(eta_j)\n",
    "    #print(loggamma(np.exp(np.sum(np.log(p_cur.la_ev)))),\n",
    "    #       loggamma(np.exp(np.sum(np.log(p_new.la_ev)))))\n",
    "    A0 = k*(loggamma(np.exp(np.sum(np.log(p_cur.la_ev))))-\n",
    "           loggamma(np.exp(np.sum(np.log(p_new.la_ev)))))\n",
    "    A1 = k*(np.sum(np.log(gamma(p_new.la_ev)))-np.sum(np.log(gamma(p_cur.la_ev))))\n",
    "    A2 = np.matmul((p_new.la_ev-1),np.log(p_new.lm_phi)).sum()-np.matmul((p_cur.la_ev-1),np.log(p_cur.lm_phi)).sum()\n",
    "    #print('A', p_cur.la_ev[0:5],np.log(p_cur.la_ev)[0:5],np.sum(np.log(p_cur.la_ev)))\n",
    "    #B: eta_j~Gamma(a0,b0)\n",
    "    a0 = 1/(2*v)\n",
    "    b0 = 1/(2*v)\n",
    "    B = (a0-1)*(np.log(p_new.la_ev)-np.log(p_cur.la_ev)).sum()+(p_cur.la_ev-p_new.la_ev).sum()/b0\n",
    "    \n",
    "    #C: theta_kl~Gamma(sk,cj)\n",
    "    C0 = j*(loggamma(p_cur.la_sk).sum()-loggamma(p_new.la_sk).sum())+(\n",
    "    p_cur.la_sk.sum()*np.log(p_cur.la_cj).sum()-p_new.la_sk.sum()*np.log(p_new.la_cj).sum())\n",
    "    #print('ration_F',p_new.lm_tht[0:2],p_cur.lm_tht[0:2])\n",
    "    C1 = np.matmul(p_new.la_sk-1,np.log(p_new.lm_tht).sum(axis=1))-np.matmul(\n",
    "        p_cur.la_sk-1,np.log(p_cur.lm_tht).sum(axis=1))\n",
    "    C2 = np.divide(p_cur.lm_tht.sum(axis=0),p_cur.la_cj).sum()-np.divide(p_new.lm_tht.sum(axis=0),p_new.la_cj).sum()\n",
    "    \n",
    "    #D: sk~Gamma(gamma0,c0), gamma0 = c0 = (v*averageExpression)^0.5\n",
    "    average4 = np.sqrt(np.sqrt(v*7.42))\n",
    "    gamma0 = average4\n",
    "    c0 = average4\n",
    "    D = (gamma0-1)*(np.log(p_new.la_sk)-np.log(p_cur.la_sk)).sum()+(p_cur.la_sk-p_new.la_sk).sum()/c0\n",
    "    \n",
    "    #E: Cj~Gamma(a1,b1)\n",
    "    a1 = average4\n",
    "    b1 = average4\n",
    "    E = (a1-1)*(np.log(p_new.la_cj)-np.log(p_cur.la_cj)).sum()+(p_cur.la_cj-p_new.la_cj).sum()/b1\n",
    "    \n",
    "    #F: gamma0~Gamma(a2,b2)\n",
    "    average8 = np.sqrt(average4)\n",
    "    a2 = average8\n",
    "    b2 = average8\n",
    "    F = (a2-1)*(np.log(p_new.ln[1])-np.log(p_cur.ln[1]))+(p_cur.ln[1]-p_new.ln[1])/b2\n",
    "    \n",
    "    #G: c0~Gamma(a3,b3)\n",
    "    a3 = average8\n",
    "    b3 = average8\n",
    "    G = (a3-1)*(np.log(p_new.ln[0])-np.log(p_cur.ln[0]))+(p_cur.ln[0]-p_new.ln[0])/b3\n",
    "    '''Likelihood'''\n",
    "    #I: n_vj~Poisson(phi_vk theta_kj)\n",
    "    I0 = np.transpose(np.log(np.matmul(p_new.lm_phi,p_new.lm_tht))-np.log(np.matmul(p_cur.lm_phi,p_cur.lm_tht)))\n",
    "    #print(I0.shape,I0[0:5],data_F.head())\n",
    "    I1 = np.multiply(data_F.as_matrix(),I0).sum()\n",
    "    I2 = (np.matmul(p_cur.lm_phi,p_cur.lm_tht)-np.matmul(p_new.lm_phi,p_new.lm_tht)).sum()\n",
    "    print('ratio - F',\"%0.2f\" % A0,\"%0.2f\" % A1,\"%0.2f\" % A2,\"%0.2f\" % B,\"%0.2f\" % C0,\n",
    "          \"%0.2f\" % C1,\"%0.2f\" % C2,\"%0.2f\" % D,\"%0.2f\" % E, \"%0.2f\" % F,\"%0.2f\" % G,\n",
    "         \"%0.2f\" % I1,\"%0.2f\" % I2,'end')\n",
    "    return (A0+A1+A2+B+C0+C1+C2+D+E+F+G+I1+I2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_p(p_new,p_cur, data_P,k,y):\n",
    "    sigma0 = 5\n",
    "    sigma = 2\n",
    "    mu0 = -len(p_new.p)\n",
    "    mu = 1\n",
    "    #H: beta~normal(mu,sigma2)\n",
    "    H0 = (1/(sigma0*sigma0))*((p_cur.p[0]-mu0)*(p_cur.p[0]-mu0)-(p_new.p[0]-mu0)*(p_new.p[0]-mu0))*0.5\n",
    "    H1 = (np.multiply((p_cur.p-mu),(p_cur.p-mu))-np.multiply((p_new.p-mu),(p_new.p-mu))).sum()\n",
    "    H1 = H1 - (p_cur.p[0]-mu)*(p_cur.p[0]-mu)+(p_new.p[0]-mu)*(p_new.p[0]-mu)\n",
    "    H1 = (H1*(len(p_new.p)-1)/sigma)*0.5\n",
    "    \n",
    "    #J: y~Log(xbeta)\n",
    "    data_P = data_P.as_matrix()\n",
    "    #print('dataP inside ratio',data_P[0:5])\n",
    "    #data_P = np.append(np.array(np.repeat(1,data_P.shape[0])), data_P, axis=1)\n",
    "    data_P = np.hstack((np.array(np.repeat(1,data_P.shape[0])).reshape(data_P.shape[0],1),data_P))\n",
    "    data_P = np.hstack((data_P,np.transpose(p_cur.lm_tht)))\n",
    "    #print('\\n lm_tht',np.transpose(p_cur.lm_tht))\n",
    "    xw_new = np.dot(data_P,p_new.p)\n",
    "    xw_cur = np.dot(data_P,p_cur.p)\n",
    "    J = (-np.log(1+np.exp(xw_new))+\n",
    "          np.dot(y,xw_new)).sum()/((-np.log(1+np.exp(xw_cur))+\n",
    "                                                        np.dot(y,xw_cur))).sum()\n",
    "    #print('ratio - P',\"%0.2f\" % H0,\"%0.2f\" % H1,\"%0.2f\" % J)\n",
    "    return (H0+H1+J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creatint the MCMC for the model\n",
    "MCMC(\n",
    "startvalue = initial value for the parameters\n",
    "iterations = \n",
    "data = complete data with all columns \n",
    "k = number of latent variables\n",
    "remove, lr, y = columns names to be removed, presente only in the logistic regression part and y\n",
    ")\n",
    "'''\n",
    "def MCMC(startvalue, iterations, data,k, lr,y):\n",
    "    #print('all',data.head())\n",
    "    '''Splitting dataset'''\n",
    "    data_P = data[lr]\n",
    "    #print('\\n P',data_P.head())\n",
    "    data_F = data.drop(lr,axis = 1)\n",
    "    data_F = data_F.drop(y,axis = 1)\n",
    "    y = data[y]\n",
    "    a_P = 0\n",
    "    a_F = 0\n",
    "    '''\n",
    "    Initialization of the chains\n",
    "    Note: chain_f has elements from chain_p and vice-versa. Take care to not use incorrectly\n",
    "    '''     \n",
    "    chain_f = []\n",
    "    chain_p = []\n",
    "    chain_f.append(startvalue)\n",
    "    chain_p.append(startvalue)\n",
    "     \n",
    "    for i in np.arange(1,iterations):\n",
    "        '''Factor Analysis - Latent Features'''\n",
    "        #use chain_f or chain_p don't make difference here because\n",
    "        #the only parameters changed are the logistic regression and \n",
    "        #they aren't used in the factor analysis part. \n",
    "        param_new_f = proposal_f(chain_f[i-1])\n",
    "        param_cur_f = chain_f[i-1] \n",
    "        if i%10 == 0: \n",
    "            a = a_F*10/i\n",
    "            b = a_P*10/i\n",
    "            print('iteration ',i,' acceptance ', \"%0.2f\" % a,'-', \"%0.2f\" % b)\n",
    "        #prob_f = np.exp(posterior(param_new_f,data_F,data_P,y,k)-posterior(param_cur_f,data_F,data_P,y,k))\n",
    "        prob_f = np.exp(ration_f(param_new_f,param_cur_f, data_F,k))\n",
    "        if np.random.uniform(0,1,1)<prob_f:\n",
    "            chain_f.append(param_new_f)\n",
    "            a_F+=1\n",
    "        else:\n",
    "            chain_f.append(param_cur_f) \n",
    "        '''Logistic Regression - Prediction'''\n",
    "        #chain_f[i] has the most update latent parameters and haven't changed the \n",
    "        #prediction parameters from [i-1] iteration\n",
    "        param_new_p = proposal_p(chain_f[i-1])\n",
    "        param_cur_p = chain_f[i-1]\n",
    "        #print(param_new_p.p[0:20],param_cur_p.p[0:20])\n",
    "        prob_p = np.exp(ratio_p(param_new_p,param_cur_p,data_P,k,y))\n",
    "        if np.random.uniform(0,1,1)<prob_p:\n",
    "            chain_p.append(param_new_p)\n",
    "            a_P+=1\n",
    "        else:\n",
    "            chain_p.append(param_cur_p)     \n",
    "\n",
    "    return chain_p, chain_f, a_P, a_F\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Non informative prioris: dirichlet has only 1, gamma distribution with 1 average, etc'''\n",
    "#UPDATE NUMBERS ACCORDING WITH POISSON AND LOG(N)\n",
    "aux = len(lr)+1\n",
    "data = data.drop(remove,axis = 1)\n",
    "v = (data.shape[1]-aux)\n",
    "j = data.shape[0]\n",
    "start = parameters([1.65,1.65], #ln [0-c0,1-gamma0]\n",
    "                   np.repeat(2.72,j), #la_cj\n",
    "                   np.repeat(2.72,k), #la_sk\n",
    "                   np.repeat(1,v), #la_ev\n",
    "                   np.repeat(1/(data.shape[1]-aux),(data.shape[1]-aux)*k).reshape((data.shape[1]-aux),k),#lm_phi v x k \n",
    "                   np.repeat(7.42,(data.shape[0])*k).reshape(k,(data.shape[0])), #lm_theta k x j\n",
    "                   np.concatenate(([-(k*7.42)], np.repeat(1,k+aux-1))))  #p, k+aux-1  because intercept is already counted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(remove,axis=1)\n",
    "start_time = time.time()\n",
    "output_p, output_f, acept_P,acept_F = MCMC(start,sim,data,k,lr,y)\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "#Don't make sense, some operations must be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(8)/2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Organizing outputs'''\n",
    "\n",
    "#TRANSFORM IN A FUNCTION TO STOP HAVE MEMORY PROBLEMS \n",
    "\n",
    "#Logistic Regression Parameters \n",
    "output_logistic = np.concatenate((output_p[0].p,output_p[1].p),axis = 0)\n",
    "#Factor Model parameters\n",
    "output_factor_ln = np.concatenate((output_f[0].ln,output_f[1].ln),axis = 0)\n",
    "output_factor_la_sk = np.concatenate((output_f[0].la_sk,output_f[1].la_sk),axis = 0)\n",
    "#Matrix AxB is saved as a line A*B elements \n",
    "output_factor_lm_phi= np.concatenate((output_f[0].lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "output_factor_lm_tht= np.concatenate((output_f[0].lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "\n",
    "\n",
    "for i in np.arange(2,sim):\n",
    "    output_logistic = np.concatenate((output_logistic,output_p[i].p),axis = 0)\n",
    "    output_factor_ln = np.concatenate((output_factor_ln,output_f[1].ln),axis = 0)\n",
    "    output_factor_la_sk = np.concatenate((output_factor_la_sk,output_f[1].la_sk),axis = 0)\n",
    "\n",
    "output_logistic = output_logistic.reshape(sim,len(output_p[0].p) )    \n",
    "output_factor_ln = output_factor_ln.reshape(sim,len(output_f[0].ln) )\n",
    "output_factor_la_sk = output_factor_la_sk.reshape(sim,len(output_f[0].la_sk) )   \n",
    "\n",
    "np.savetxt('Data\\\\output_logistic.txt', output_logistic, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_ln.txt', output_factor_ln, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_la_sk.txt', output_factor_la_sk, delimiter=',')  \n",
    "\n",
    "'''\n",
    "    output_factor_lm_phi = np.concatenate((output_factor_lm_phi,output_f[1].lm_phi),axis = 0)\n",
    "    output_factor_lm_tht = np.concatenate((output_factor_lm_tht,output_f[1].lm_tht),axis = 0)\n",
    "    \n",
    "output_factor_lm_phi = output_factor_lm_phi.reshape(sim,output_f[0].lm_phi.shape[0]*output_f[0].lm_phi.shape[1])   \n",
    "output_factor_lm_tht = output_factor_lm_tht.reshape(sim,output_f[0].lm_tht.shape[0]*output_f[0].lm_tht.shape[1])\n",
    "\n",
    "np.savetxt('Data\\\\output_factor_lm_phi.txt', output_factor_lm_phi, delimiter=',')  \n",
    "np.savetxt('Data\\\\output_factor_lm_tht.txt', output_factor_lm_tht, delimiter=',')  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acceptance and rejection  problem \n",
    "#create a easy way to identify paramerters based on name\n",
    "#test several parameters at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(0,len(output_logistic[:,0])),output_logistic[:,0], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - intercept')\n",
    "plt.savefig('Data\\\\lr_intercept.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,1])),output_logistic[:,1], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - gender')\n",
    "plt.savefig('Data\\\\lr_gender.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,10])),output_logistic[:,10], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - cancer type (one of them)')\n",
    "plt.savefig('Data\\\\lr_cancertype.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_logistic[:,30])),output_logistic[:,30], 'r-', alpha=1)\n",
    "plt.xlabel('Logistic Regression - k (one of them)')\n",
    "plt.savefig('Data\\\\lr_k.png')\n",
    "\n",
    "plt.plot(np.arange(0,len(output_factor_ln[:,2])),output_factor_ln[:,2], 'r-', alpha=1)\n",
    "plt.xlabel('Factor Analysis - parameter')\n",
    "plt.savefig('Data\\\\fa_1.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
